{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ass=1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZmJjSNrTxA4",
        "outputId": "7d4ceba8-ebfb-4d2e-83bd-8ea13357577a"
      },
      "source": [
        "# given function is pow(x,4)+3*pow(x,2)+10\n",
        "\n",
        "x = 3 # initial x value\n",
        "learning_rate = 0.01 # learning rate\n",
        "print(\"learning rate : \",learning_rate)\n",
        "print(\"Initial x : \",x)\n",
        "\n",
        "print(\"\\nEpoch 1\")\n",
        "gradient_f_at_x = (4*x**3 + 6*x)\n",
        "print(\"gradient_f_at_x : \",gradient_f_at_x)\n",
        "delta_x = -1*learning_rate*gradient_f_at_x\n",
        "print(\"delta_x : \",delta_x)\n",
        "x = x + delta_x\n",
        "print(\"x : \",x)\n",
        "\n",
        "print(\"\\nEpoch 2\")\n",
        "gradient_f_at_x = (4*x**3 + 6*x)\n",
        "print(\"gradient_f_at_x : \",gradient_f_at_x)\n",
        "delta_x = -1*learning_rate*gradient_f_at_x\n",
        "print(\"delta_x : \",delta_x)\n",
        "x = x + delta_x\n",
        "print(\"x : \",x)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate :  0.01\n",
            "Initial x :  3\n",
            "\n",
            "Epoch 1\n",
            "gradient_f_at_x :  126\n",
            "delta_x :  -1.26\n",
            "x :  1.74\n",
            "\n",
            "Epoch 2\n",
            "gradient_f_at_x :  31.512096\n",
            "delta_x :  -0.31512096\n",
            "x :  1.42487904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qECJVX2sVJ2T"
      },
      "source": [
        "# given function is pow(x,4)+3*pow(x,2)+10\n",
        "\n",
        "x = 3 # initial x value\n",
        "learning_rate = 0.01 # learning rate\n",
        "epochs = 100 # number of epochs\n",
        "\n",
        "# function to find the gradient descent\n",
        "def gradient(x):\n",
        "  return 4*pow(x,3)+6*x\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVY6Z4DDVg9H"
      },
      "source": [
        "# training loop\n",
        "for i in range(0,epochs):\n",
        "  grad = gradient(x)\n",
        "  delta_x = -1*learning_rate*grad\n",
        "  x = x + delta_x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjtid_JwV2j2",
        "outputId": "ed68ee03-c851-45b6-d5d7-eb084dbc285b"
      },
      "source": [
        "# optimal value of x\n",
        "print(x)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.002069222197565439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBbtI-YuWDY0",
        "outputId": "0724ade9-eefa-4260-cfdd-f2ae71c33823"
      },
      "source": [
        "# minimal value of the given function\n",
        "print(pow(x,4)+3*pow(x,2)+10)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.00001284505984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frk4IlOWWPTm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}